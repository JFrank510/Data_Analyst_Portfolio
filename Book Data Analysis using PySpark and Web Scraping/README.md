# Book Data Analysis using PySpark and Web Scraping
This project aims to use web scraping and PySpark techniques to analyze and visualize data on books gathered from an online platform.

## Installation
To run this project, you must have PySpark installed along with the following Python libraries:

- Requests
- BeautifulSoup
- Pandas

## Usage
To use this project, simply download the "book_analysis.ipynb" file and upload it to your Google Drive. Then, open the file in Google Colab and follow the instructions in the notebook.

This file takes care of collecting data on books from an online platform using web scraping, analyzing and visualizing this data using PySpark and Python libraries such as Pandas.

## Tools Used
This project uses the following tools:

- Jupyter Notebook: Web-based interactive development environment for creating notebooks.
- Google Colab: Free cloud-based service for running Jupyter Notebook files.
- Python: Programming language used to write the code.
- PySpark: Library used for distributed data processing.
- Requests: Library used for making HTTP requests to gather book data online.
- BeautifulSoup: Library used for parsing and extracting data from HTML and XML.
- Pandas: Library used for data analysis and manipulation in Python.
