{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSOQANYAltIy"
      },
      "source": [
        "# Instrucciones:\n",
        "\n",
        "1. Antes de comenzar, realiza una copia de este **Google Colab Notebook** en tu propia cuenta de Google Drive. De lo contrario, no se podrá guardar ningún cambio.\n",
        "2. En el título, agrega tu nombre en el espacio correspondiente. \n",
        "3. Una vez terminado, exporta tus resultados en formato PDF. Pasos: Archivo > Imprimir > Imprimir en archivo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeRMBGZum7qS"
      },
      "source": [
        "# Python\n",
        "\n",
        "#### 1. Crea una función llamada **search** que buscará cualquier término de búsqueda en la Base de Datos de Wikipedia y devolverá el resultado de dicha consulta. Posteriormente ejecuta lo siguiente:\n",
        "- La función recibe como único parámetro de entrada: **search_term** que representa el término a buscar .\n",
        "- La función tendrá como salida un resultado de tipo JSON llamado **response_content** con el contenido de respuesta de la API. \n",
        "- Imprimir el resultado en pantalla\n",
        "\n",
        "> Input (Type String): search_term\n",
        ">\n",
        "> Output (Type JSON): response_content\n",
        "\n",
        "[Documentación](https://www.mediawiki.org/wiki/API:Search#GET_request)\n",
        "#### Para el siguiente ejercicio, usa la libreria **requests** de python para conectarse a la API RESTful de Wikipedia\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2DSs7IGlu3m",
        "outputId": "6497a3d4-a178-4eb8-b36f-83a6e6ef8477"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batchcomplete': '',\n",
              " 'continue': {'sroffset': 10, 'continue': '-||'},\n",
              " 'query': {'searchinfo': {'totalhits': 65901},\n",
              "  'search': [{'ns': 0,\n",
              "    'title': 'Big data',\n",
              "    'pageid': 27051151,\n",
              "    'size': 157231,\n",
              "    'wordcount': 15455,\n",
              "    'snippet': '<span class=\"searchmatch\">Big</span> <span class=\"searchmatch\">data</span> primarily refers to <span class=\"searchmatch\">data</span> sets that are too large or complex to be dealt with by traditional <span class=\"searchmatch\">data</span>-processing application software. <span class=\"searchmatch\">Data</span> with many',\n",
              "    'timestamp': '2023-02-15T17:29:06Z'},\n",
              "   {'ns': 0,\n",
              "    'title': 'Data',\n",
              "    'pageid': 18985040,\n",
              "    'size': 20432,\n",
              "    'wordcount': 2451,\n",
              "    'snippet': 'to the advent of <span class=\"searchmatch\">big</span> <span class=\"searchmatch\">data</span>, which usually refers to very large quantities of <span class=\"searchmatch\">data</span>, usually at the petabyte scale. Using traditional <span class=\"searchmatch\">data</span> analysis methods',\n",
              "    'timestamp': '2023-02-18T03:04:50Z'},\n",
              "   {'ns': 0,\n",
              "    'title': 'Big Data (band)',\n",
              "    'pageid': 41460310,\n",
              "    'size': 8976,\n",
              "    'wordcount': 351,\n",
              "    'snippet': '<span class=\"searchmatch\">Big</span> <span class=\"searchmatch\">Data</span> is an American electronic music project created by producer Alan Wilkis. <span class=\"searchmatch\">Big</span> <span class=\"searchmatch\">Data</span> is best known for the single &quot;Dangerous&quot;, featuring Joywave',\n",
              "    'timestamp': '2022-04-29T02:47:48Z'},\n",
              "   {'ns': 0,\n",
              "    'title': 'Data science',\n",
              "    'pageid': 35458904,\n",
              "    'size': 19299,\n",
              "    'wordcount': 1849,\n",
              "    'snippet': 'consensus on the definition of <span class=\"searchmatch\">data</span> science, and it is considered by some to be a buzzword. <span class=\"searchmatch\">Big</span> <span class=\"searchmatch\">data</span> is a related marketing term. <span class=\"searchmatch\">Data</span> scientists are responsible',\n",
              "    'timestamp': '2023-02-12T02:13:45Z'},\n",
              "   {'ns': 0,\n",
              "    'title': 'Big data ethics',\n",
              "    'pageid': 55181525,\n",
              "    'size': 19091,\n",
              "    'wordcount': 2209,\n",
              "    'snippet': '<span class=\"searchmatch\">Big</span> <span class=\"searchmatch\">data</span> ethics also known as simply <span class=\"searchmatch\">data</span> ethics refers to systemizing, defending, and recommending concepts of right and wrong conduct in relation to',\n",
              "    'timestamp': '2023-02-07T19:31:28Z'},\n",
              "   {'ns': 0,\n",
              "    'title': 'List of big data companies',\n",
              "    'pageid': 51354460,\n",
              "    'size': 2933,\n",
              "    'wordcount': 320,\n",
              "    'snippet': 'marketing term <span class=\"searchmatch\">big</span> <span class=\"searchmatch\">data</span>: Alpine <span class=\"searchmatch\">Data</span> Labs, an analytics interface working with Apache Hadoop and <span class=\"searchmatch\">big</span> <span class=\"searchmatch\">data</span> Azure <span class=\"searchmatch\">Data</span> Lake is a highly scalable <span class=\"searchmatch\">data</span> storage and',\n",
              "    'timestamp': '2023-01-19T12:19:02Z'},\n",
              "   {'ns': 0,\n",
              "    'title': 'Industrial big data',\n",
              "    'pageid': 48415691,\n",
              "    'size': 15260,\n",
              "    'wordcount': 1365,\n",
              "    'snippet': 'Asif Jamal mansoori Industrial <span class=\"searchmatch\">big</span> <span class=\"searchmatch\">data</span> refers to a large amount of diversified time series generated at a high speed by industrial equipment, known as',\n",
              "    'timestamp': '2023-02-08T05:27:14Z'},\n",
              "   {'ns': 0,\n",
              "    'title': 'Data lake',\n",
              "    'pageid': 46626475,\n",
              "    'size': 8264,\n",
              "    'wordcount': 929,\n",
              "    'snippet': 'technologist at HP\\'s <span class=\"searchmatch\">Big</span> <span class=\"searchmatch\">Data</span> Business Unit, discussed one of the more controversial ways to manage <span class=\"searchmatch\">big</span> <span class=\"searchmatch\">data</span>, so-called <span class=\"searchmatch\">data</span> lakes. &quot;Are <span class=\"searchmatch\">Data</span> Lakes Fake News',\n",
              "    'timestamp': '2023-01-26T16:06:03Z'},\n",
              "   {'ns': 0,\n",
              "    'title': 'Data analysis',\n",
              "    'pageid': 2720954,\n",
              "    'size': 84663,\n",
              "    'wordcount': 9156,\n",
              "    'snippet': '<span class=\"searchmatch\">Big</span> <span class=\"searchmatch\">data</span> Business intelligence Censoring (statistics) Computational physics Computational science <span class=\"searchmatch\">Data</span> acquisition <span class=\"searchmatch\">Data</span> blending <span class=\"searchmatch\">Data</span> governance <span class=\"searchmatch\">Data</span>',\n",
              "    'timestamp': '2023-02-16T00:57:41Z'},\n",
              "   {'ns': 0,\n",
              "    'title': 'Data set',\n",
              "    'pageid': 8495,\n",
              "    'size': 8214,\n",
              "    'wordcount': 848,\n",
              "    'snippet': '(2012). &quot;\\'<span class=\"searchmatch\">Big</span> <span class=\"searchmatch\">Data</span>\\': <span class=\"searchmatch\">Big</span> gaps of knowledge in the field of Internet&quot;. International Journal of Internet Science. 7: 1–5. &quot;European open <span class=\"searchmatch\">data</span> portal&quot;. European',\n",
              "    'timestamp': '2023-02-13T02:47:46Z'}]}}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "try:\n",
        "  import requests\n",
        "  import pandas as pd\n",
        "  import json\n",
        "  import requests\n",
        "except ImportError as eImp:\n",
        "    print(f\"Se produjo un error al importar las siguientes librerias: {eImp}\")\n",
        "\n",
        "def search(search_term):\n",
        "  se = requests.Session()\n",
        "  URL = \"https://en.wikipedia.org/w/api.php\"\n",
        "  PARAMS = {\n",
        "    \"action\": \"query\",\n",
        "    \"format\": \"json\",\n",
        "    \"list\": \"search\",\n",
        "    \"srsearch\": search_term\n",
        "  } \n",
        "  response_content = se.get(url=URL, params=PARAMS)\n",
        "  response_content = response_content.json()\n",
        "  return response_content\n",
        "  \n",
        "# Ejemplo\n",
        "search(\"Big Data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmY2zqGMoxvk"
      },
      "source": [
        "#### 2. Construye una función llamada **get_results_table** que tomará como entrada el resultado de la función **search** y tendrá como salida un **Data Frame** de la librería Pandas. Posteriormente ejecuta lo siguiente:\n",
        "- La función recibe como parámetro de entrada la salida de la función **search** \n",
        "- La función tendrá como salida un Data Frame de Pandas llamado **df**\n",
        "- Elimina las columnas **ns, snippet** como regla de negocio.\n",
        "- Agrega una columna llamada **search_term** que contenga el término buscado\n",
        "- Imprimir el resultado en pantalla\n",
        "- Guarda el resultado en un archivo **CSV** llamado **salida.csv** (Si lo ejecutas en Drive, se deberá cargar en el folder */content*)\n",
        "\n",
        "   >Input (Type String): output_call_search\n",
        "   >\n",
        "   >Output (Type Pandas Data Frame): df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "34jyVRqDpCOD"
      },
      "outputs": [],
      "source": [
        "def get_results_table(output_call_search):\n",
        "    columns_to_delete = ['snippet', 'ns']\n",
        "    dfx = pd.DataFrame.from_records(output_call_search['query']['search'])\n",
        "    dfx.drop(columns_to_delete, axis='columns', inplace=True)\n",
        "    df=dfx.assign(search_term = search_term)\n",
        "    df=dfx.assign(search_term = search_term)\n",
        "    df.to_csv('./salida.csv')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uOVifezZpycE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "e2169704-3f17-45d9-99e3-b87f3329c197"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        title    pageid    size  wordcount  \\\n",
              "0                    Big data  27051151  157231      15455   \n",
              "1                        Data  18985040   20432       2451   \n",
              "2             Big Data (band)  41460310    8976        351   \n",
              "3                Data science  35458904   19299       1849   \n",
              "4             Big data ethics  55181525   19091       2209   \n",
              "5  List of big data companies  51354460    2933        320   \n",
              "6         Industrial big data  48415691   15260       1365   \n",
              "7                   Data lake  46626475    8264        929   \n",
              "8               Data analysis   2720954   84663       9156   \n",
              "9                    Data set      8495    8214        848   \n",
              "\n",
              "              timestamp search_term  \n",
              "0  2023-02-15T17:29:06Z    Big Data  \n",
              "1  2023-02-18T03:04:50Z    Big Data  \n",
              "2  2022-04-29T02:47:48Z    Big Data  \n",
              "3  2023-02-12T02:13:45Z    Big Data  \n",
              "4  2023-02-07T19:31:28Z    Big Data  \n",
              "5  2023-01-19T12:19:02Z    Big Data  \n",
              "6  2023-02-08T05:27:14Z    Big Data  \n",
              "7  2023-01-26T16:06:03Z    Big Data  \n",
              "8  2023-02-16T00:57:41Z    Big Data  \n",
              "9  2023-02-13T02:47:46Z    Big Data  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1588f075-0f52-4a04-891b-0a5bb788249a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>pageid</th>\n",
              "      <th>size</th>\n",
              "      <th>wordcount</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>search_term</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Big data</td>\n",
              "      <td>27051151</td>\n",
              "      <td>157231</td>\n",
              "      <td>15455</td>\n",
              "      <td>2023-02-15T17:29:06Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data</td>\n",
              "      <td>18985040</td>\n",
              "      <td>20432</td>\n",
              "      <td>2451</td>\n",
              "      <td>2023-02-18T03:04:50Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Big Data (band)</td>\n",
              "      <td>41460310</td>\n",
              "      <td>8976</td>\n",
              "      <td>351</td>\n",
              "      <td>2022-04-29T02:47:48Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data science</td>\n",
              "      <td>35458904</td>\n",
              "      <td>19299</td>\n",
              "      <td>1849</td>\n",
              "      <td>2023-02-12T02:13:45Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Big data ethics</td>\n",
              "      <td>55181525</td>\n",
              "      <td>19091</td>\n",
              "      <td>2209</td>\n",
              "      <td>2023-02-07T19:31:28Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>List of big data companies</td>\n",
              "      <td>51354460</td>\n",
              "      <td>2933</td>\n",
              "      <td>320</td>\n",
              "      <td>2023-01-19T12:19:02Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Industrial big data</td>\n",
              "      <td>48415691</td>\n",
              "      <td>15260</td>\n",
              "      <td>1365</td>\n",
              "      <td>2023-02-08T05:27:14Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Data lake</td>\n",
              "      <td>46626475</td>\n",
              "      <td>8264</td>\n",
              "      <td>929</td>\n",
              "      <td>2023-01-26T16:06:03Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Data analysis</td>\n",
              "      <td>2720954</td>\n",
              "      <td>84663</td>\n",
              "      <td>9156</td>\n",
              "      <td>2023-02-16T00:57:41Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Data set</td>\n",
              "      <td>8495</td>\n",
              "      <td>8214</td>\n",
              "      <td>848</td>\n",
              "      <td>2023-02-13T02:47:46Z</td>\n",
              "      <td>Big Data</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1588f075-0f52-4a04-891b-0a5bb788249a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1588f075-0f52-4a04-891b-0a5bb788249a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1588f075-0f52-4a04-891b-0a5bb788249a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "search_term = \"Big Data\"\n",
        "results = search(search_term)\n",
        "get_results_table(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKDiHhen2Y8Q"
      },
      "source": [
        "# Spark\n",
        "#### **! Asegurate de tener lo siguiente.**\n",
        "- Actualiza el archivo **csv**  del ejercicio anterior dentro de los archivos de este notebook (/content/file.csv).\n",
        "- Ejecuta el siguiente *chunk* para instalar Spark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kyuLgm9FyMxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fecc3494-2e74-4e49-bda7-389a21e0694c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=f4a9f0e0b9eb8e80d4c95bf0cb12bd104dad62f0f3c1c16ace28d5e3ed5fe792\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhkB7G87yuBr"
      },
      "source": [
        "#### 1. Crea una función llamada **main** que construya un Data Frame de Spark con base en el archivo CSV anterior. Posteriormente ejecuta lo siguiente:\n",
        "- La función recibe como parámetro: **path** que es la ruta del archivo CSV.\n",
        "- La función tendrá como salida un Data Frame de spark\n",
        "- Elimina las columnas **ns, snippet** como regla de negocio.\n",
        "- Ordena las columas de la siguiente forma: Title, Timestamp, Wordcount\n",
        "- Cambia el nombre de las columnas manteniendo el mismo orden el punto anterior: Título, Date, Word Count\n",
        "- Ordena la tabla del dato más reciente hasta el más antiguo mediante el campo **timestamp**\n",
        "- Imprime el resultado en pantalla\n",
        "\n",
        "> Input (Type String): path\n",
        ">\n",
        "> Output (Type JSON): df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UsnHdm7IyN-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e901ef-b95b-4caf-9d3f-73b2fd55df7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+----------+--------+------+-----------+\n",
            "|              Titulo|               Date|Word Count|  pageid|  size|search_term|\n",
            "+--------------------+-------------------+----------+--------+------+-----------+\n",
            "|     Big Data (band)|2022-04-29 02:47:48|       351|41460310|  8976|   Big Data|\n",
            "|List of big data ...|2023-01-19 12:19:02|       320|51354460|  2933|   Big Data|\n",
            "|           Data lake|2023-01-26 16:06:03|       929|46626475|  8264|   Big Data|\n",
            "|     Big data ethics|2023-02-07 19:31:28|      2209|55181525| 19091|   Big Data|\n",
            "| Industrial big data|2023-02-08 05:27:14|      1365|48415691| 15260|   Big Data|\n",
            "|        Data science|2023-02-12 02:13:45|      1849|35458904| 19299|   Big Data|\n",
            "|            Data set|2023-02-13 02:47:46|       848|    8495|  8214|   Big Data|\n",
            "|            Big data|2023-02-15 17:29:06|     15455|27051151|157231|   Big Data|\n",
            "|       Data analysis|2023-02-16 00:57:41|      9156| 2720954| 84663|   Big Data|\n",
            "|                Data|2023-02-18 03:04:50|      2451|18985040| 20432|   Big Data|\n",
            "+--------------------+-------------------+----------+--------+------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import pandas as pd\n",
        "  from pyspark.sql import SparkSession\n",
        "  from pyspark.sql.functions import to_timestamp\n",
        "except ImportError as eImp:\n",
        "  print(f\"Se produjo un error al importar las siguientes librerias: {eImp}\")\n",
        "\n",
        "spark = SparkSession.builder.appName(\"App - Ingeniería de Datos\").getOrCreate()\n",
        "    \n",
        "def main(path):\n",
        "  df = spark.read.csv(path,header=True)\n",
        "  df = df[['title','timestamp','wordcount','pageid','size','search_term']]\n",
        "  df = df.withColumnRenamed(\"title\", \"Titulo\")\n",
        "  df = df.withColumnRenamed(\"timestamp\", \"Date\")\n",
        "  df = df.withColumnRenamed(\"wordcount\", \"Word Count\")\n",
        "  df = df.withColumn(\"Date\",to_timestamp(\"Date\"))\n",
        "  df = df.sort(('Date'))\n",
        "  df.show()\n",
        "path ='/content/salida.csv'  \n",
        "main(path)\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXBPl3QPE3Xs"
      },
      "source": [
        "# SQL\n",
        "En esta sección, usarás dos conjuntos de datos de código abierto para responder unas preguntas más adelante: \n",
        "- **flights.csv**: contiene 100k registros de vuelos del año 2015 dentro de Estados Unidos. \n",
        "- **airports.csv**: catálogo de aeropuertos en Estados Unidos\n",
        "\n",
        "Ambos datasets se encuentran disponibles en el siguiente [Enlace](https://drive.google.com/drive/folders/1vjeel7rQQs6gqLTTZKuHdePnHHSzDzfS?usp=sharing).\n",
        "\n",
        "#### ! Asegurate de tener lo siguiente.\n",
        "- Datasets alojados en /content/file.csv (si lo ejecutas en Drive)\n",
        "- Ejecuta el *chunk* anterior para instalar Spark\n",
        "\n",
        "\n",
        "Realiza lo siguiente:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpxt12FtiljQ"
      },
      "source": [
        "#### **Contexto**: \n",
        "La Oficina de Estadísticas de Transporte del Departamento de Transporte de EE. UU. (DOT) rastrea el desempeño puntual de los vuelos nacionales operados por grandes compañías aéreas. La información resumida sobre el número de vuelos puntuales, retrasados, cancelados y desviados se publica en el Informe del consumidor de viajes aéreos mensual del DOT y en este conjunto de datos de retrasos y cancelaciones de vuelos de 2015."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svo3wa3ejoge"
      },
      "source": [
        "1. Realiza un recuerdo del número de vuelos entre un aeropuerto de origen (origin_airport) y un aeropuerto de destino (destination_airport) con retraso de salida (departure_delay) pero que llegaron a tiempo (arrival_delay). Agrega el nombre del aeropuerto disponible en el campo airport de dataset de airports."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHzpF61pjT2X"
      },
      "source": [
        "2. Calcular el promedio diario de tiempo de vuelo (air_time) entre la ruta de San Francisco (origin_airport = 'SFO') y Los Ángeles (destination_airport='LAX')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Encontrar la aerolínea y el motivo de cancelación más frecuente en los vuelos que fueron cancelados en el año 2015. La columna FREQUENCY indica el motivo de cancelación más frecuente para cada aerolínea, y puede tomar uno de los siguientes valores: \n",
        "- A: que significa cancelación por razones del operador de la aerolínea .\n",
        "\n",
        "- B: que significa cancelación por razones técnicas.\n",
        "\n",
        "- C: que significa cancelación por razones de seguridad.\n",
        "\n",
        "- D: que significa cancelación debido a las condiciones climáticas. \n",
        "\n",
        "\n",
        "> Debe mostrar las aerolíneas que tuvieron la mayor frecuencia de cancelaciones por cada uno de estos motivos. Si hay varias aerolíneas con la misma frecuencia máxima, la consulta debe mostrar todas ellas. Los resultados deben estar ordenados en orden descendente según la frecuencia máxima de cancelaciones.\n",
        "\n"
      ],
      "metadata": {
        "id": "qXt9WWsw0eBi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8YKCFuujlYV"
      },
      "source": [
        "**Para ambas consultas, imprime el resultado en pantalla**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6Ye4UBLZjiRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8368801b-c161-4152-d86b-1b387248fbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------------+-------------+\n",
            "| ORIGIN_AIRPORT_NAME|DESTINATION_AIRPORT_NAME|NUMBERFLIGHTS|\n",
            "+--------------------+------------------------+-------------+\n",
            "|Dallas/Fort Worth...|    Los Angeles Inter...|           31|\n",
            "|San Francisco Int...|    Chicago O'Hare In...|           30|\n",
            "|John F. Kennedy I...|    Los Angeles Inter...|           29|\n",
            "|Newark Liberty In...|    San Francisco Int...|           29|\n",
            "|Chicago O'Hare In...|    Los Angeles Inter...|           28|\n",
            "|Los Angeles Inter...|    San Francisco Int...|           27|\n",
            "|George Bush Inter...|    San Francisco Int...|           27|\n",
            "|Chicago O'Hare In...|    LaGuardia Airport...|           26|\n",
            "|Fort Lauderdale-H...|    Hartsfield-Jackso...|           26|\n",
            "|Los Angeles Inter...|    Chicago O'Hare In...|           24|\n",
            "|Los Angeles Inter...|    John F. Kennedy I...|           24|\n",
            "|San Francisco Int...|    John F. Kennedy I...|           23|\n",
            "|San Francisco Int...|    Los Angeles Inter...|           23|\n",
            "|Chicago O'Hare In...|    Dallas/Fort Worth...|           22|\n",
            "|Hartsfield-Jackso...|    Orlando Internati...|           22|\n",
            "|LaGuardia Airport...|    Hartsfield-Jackso...|           21|\n",
            "|McCarran Internat...|    San Francisco Int...|           21|\n",
            "|Chicago O'Hare In...|    San Francisco Int...|           21|\n",
            "|San Francisco Int...|    Washington Dulles...|           20|\n",
            "|Hartsfield-Jackso...|    Tampa Internation...|           19|\n",
            "+--------------------+------------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----------------------+\n",
            "|promedio_diario_tiempo|\n",
            "+----------------------+\n",
            "|     55.95528455284553|\n",
            "+----------------------+\n",
            "\n",
            "+-------+---------+\n",
            "|AIRLINE|FREQUENCY|\n",
            "+-------+---------+\n",
            "|     WN|        D|\n",
            "|     DL|        C|\n",
            "|     OO|        C|\n",
            "|     EV|        C|\n",
            "|     AA|        C|\n",
            "|     UA|        C|\n",
            "|     US|        C|\n",
            "|     VX|        C|\n",
            "|     MQ|        C|\n",
            "|     B6|        C|\n",
            "|     NK|        C|\n",
            "|     AS|        B|\n",
            "|     F9|        B|\n",
            "|     HA|        A|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import pandas as pd\n",
        "  from pyspark.sql import SparkSession\n",
        "except ImportError as eImp:\n",
        "  print(f\"Se produjo un error al importar las siguientes librerias: {eImp}\")\n",
        "\n",
        "spark = SparkSession.builder.appName(\"App - Ingeniería de Datos\").getOrCreate()\n",
        "def fly():\n",
        "  flights = spark.read.csv('/content/flights.csv', header=True)\n",
        "  airlines = spark.read.csv('/content/airports.csv', header=True)\n",
        "  flights.createOrReplaceTempView('flights')\n",
        "  airlines.createOrReplaceTempView('airlines')\n",
        "  query = \"\"\"\n",
        "  SELECT a1.AIRPORT AS ORIGIN_AIRPORT_NAME, a2.AIRPORT AS DESTINATION_AIRPORT_NAME, COUNT(*) AS NUMBERFLIGHTS \n",
        "  FROM flights f\n",
        "  JOIN airlines a1 ON f.ORIGIN_AIRPORT = a1.IATA_CODE\n",
        "  JOIN airlines a2 ON f.DESTINATION_AIRPORT = a2.IATA_CODE\n",
        "  WHERE f.DEPARTURE_DELAY > 0 AND f.ARRIVAL_DELAY <= 0 \n",
        "  GROUP BY ORIGIN_AIRPORT_NAME, DESTINATION_AIRPORT_NAME \n",
        "  ORDER BY NUMBERFLIGHTS DESC\n",
        "  \"\"\"\n",
        "  query2= \"\"\"\n",
        "  SELECT AVG(AIR_TIME) AS promedio_diario_tiempo\n",
        "  FROM flights\n",
        "  WHERE ORIGIN_AIRPORT = 'SFO'\n",
        "  AND DESTINATION_AIRPORT = 'LAX'\n",
        "  AND CANCELLED = 0\n",
        "  AND AIR_TIME > 0\n",
        "  \"\"\"\n",
        "  query3 =\"\"\"\n",
        "  SELECT AIRLINE, MAX(CANCELLATION_REASON) AS FREQUENCY \n",
        "  FROM flights \n",
        "  WHERE CANCELLED = 1 AND YEAR = 2015 \n",
        "  GROUP BY AIRLINE \n",
        "  ORDER BY FREQUENCY DESC;\n",
        "  \"\"\"\n",
        "  view_query = spark.sql(query)\n",
        "  view_query.show()\n",
        "  view_query2 = spark.sql(query2)\n",
        "  view_query2.show()\n",
        "  view_query3 = spark.sql(query3)\n",
        "  view_query3.show()\n",
        "fly()\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}